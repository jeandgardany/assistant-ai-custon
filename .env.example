# Configurações de Chunks
CHUNK_SIZE=1000     # Tamanho máximo de cada chunk em caracteres
CHUNK_OVERLAP=100   # Quantidade de caracteres de sobreposição entre chunks

# Configurações do Ollama
OLLAMA_BASE_URL=http://localhost:11434

# Configurações de Logging
LOG_LEVEL=INFO

# Configurações de GPU
USE_GPU=true        # Tentar usar GPU se disponível
GPU_BATCH_SIZE=32   # Tamanho do batch para processamento em GPU

# Configurações do Banco de Dados
DATABASE_FILE=data.db

# Configurações de Processamento
MAX_WORKERS=4       # Número máximo de workers para processamento paralelo
TIMEOUT=30         # Timeout em segundos para requisições

# Configurações do Modelo
MODEL_NAME=mistral  # Nome do modelo Ollama a ser usado
TEMPERATURE=0.7     # Temperatura para geração de texto
MAX_TOKENS=2048     # Número máximo de tokens na resposta
